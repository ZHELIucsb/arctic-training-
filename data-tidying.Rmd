---
title: "Data Reformatting"
author: "Zhe Li"
date: "2/13/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=FALSE, message=FALSE}
library(dplyr)
library(tidyr)
library(rlang)
# to call stats filter = stats::filter()
```

# Reformat Catch Data

* remove "all" column
* creat species column 
    - move from wide to long
* general QA

[Mike Byerly. Alaska commercial salmon catches by management region (1886- 1997). Gulf of Alaska Data Portal. df35b.304.2.](https://knb.ecoinformatics.org/view/df35b.304.2)
```{r}
# the method to read data from URL link
catch_original <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1", method = "libcurl"),
                    stringsAsFactors = FALSE)
head(catch_original)
```

Remove the `all` and `notesRegCode` columns using `select` 

Cmd + shift + m : pipe operator shortcut %>%

```{r}
catch_long <- catch_original %>% 
  select(Region, Year, Chinook, Sockeye, Coho, Pink, Chum)
# also can use another script
#  seleect(-All, -notesRegCode)
catch_long <- catch_long %>%
  gather(key = "species", value = "catch", 
         # -Region, -Year,
         Chinook, Sockeye, Pink, Chum, Coho)

head(catch_long)
```

```{r}
catch_wide <- catch_long %>%
  spread(key = species, value = catch)

head(catch_wide)
```

# Clean up your data

* rename catch to catch_thousands
* change catch colum to numeric 
* creat a new catch column in units num. of fish

```{r}
catch_clean <- catch_long %>%
  rename(catch_thousands = catch) %>%
  mutate(catch_thousands = ifelse(catch_thousands == "I",1,catch_thousands)) %>%
  mutate(catch_thousands = as.numeric(catch_thousands)) %>%
  mutate(catch = catch_thousands * 1000)
catch_clean <- catch_clean %>%
  select(-catch_thousands)

head(catch_clean)
```

```{r}
test <- as.numeric(catch_long$catch)
i <- which(is.na(test) == TRUE)
catch_long[i,]
```

## split = Applu - Combine

* calculate mean catch by species

```{r}
species_mean <- catch_clean %>%
  group_by(species, Region) %>%
  summarise(catch_mean = mean(catch),
            num_obs = length(which(is.na(catch) == F)))

head(species_mean)
```

```{r}
year_mean <- catch_clean %>%
  group_by(Year) %>%
  summarize(catch_mean = mean(catch)) %>%
  arrange(-Year) %>%
  filter(Year <= 1990 | Year >= 1960) # & this is or

year_mean
```

# Join the Region Definitions

Read in the regions dataframe

```{r}
region_defs <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.303.1", method = "libcurl"),
              stringsAsFactors = FALSE) %>% 
    select(code, mgmtArea)
#    rename(Region = code)

head(region_defs)
```

```{r}
catch_joined <- left_join(catch_clean, region_defs, by = c("Region" = "code"))

head(catch_joined)
```


# Misc. Functions

```{r}
dates_df <- data.frame(date = c("5/24/1930",
                                "5/25/1930",
                                "5/26/1930",
                                "5/27/1930",
                                "5/28/1930"),
                       stringsAsFactors = FALSE)
```

```{r}
dates_split <- dates_df %>%
  separate(date, into = c("month", "day", "year"), sep = "/", remove = F)

head(dates_split)
```

```{r}
isls <- data.frame(city = c("ALA-02",
                                 "ALA-03",
                                 "GUG-12",
                                 "GUA-21",
                                 "GUA-12"),
                        stringsAsFactors = FALSE)
isls <- isls %>%
  separate(city, into = c("island","site"))

isls
```

```{r}
library(stringr)

month <- c("5","05","03")

str_pad(month, 2, side = "left", pad = "0")
```

```{r}
write.csv(catch_clean, "catch_clean.csv", row.names = F)
```


```{r}
dates_unite <- dates_split %>%
  unite(col = data_iso, year, month, day, sep = '-')

head(dates_unite)
```







